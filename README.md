# ğŸ“Š DataYoti Analytics

> Plateforme d'analyse et de Business Intelligence pour le monitoring environnemental IoT

**DataYoti Analytics** est une solution complÃ¨te d'entreposage de donnÃ©es (Data Warehouse) et d'analyse pour les systÃ¨mes IoT de monitoring environnemental (tempÃ©rature, humiditÃ©). Le projet implÃ©mente une architecture moderne **ELT** (Extract-Load-Transform) avec orchestration dÃ©clarative et transformations testÃ©es.

---

## ï¿½ Objectif du projet

Fournir une plateforme analytique robuste permettant de :

- ğŸ“ˆ **Analyser** les tendances environnementales (tempÃ©rature, humiditÃ©) sur des pÃ©riodes Ã©tendues
- ğŸ” **Surveiller** la santÃ© et la disponibilitÃ© des capteurs IoT dÃ©ployÃ©s
- âœ… **VÃ©rifier** la conformitÃ© des conditions environnementales par rapport aux rÃ¨gles mÃ©tier
- ğŸ“Š **AgrÃ©ger** les mÃ©triques par site, par appareil et par pÃ©riode
- ğŸ¢ **Historiser** les changements de configuration (SCD Type 2)
- ğŸ“‰ **Produire** des rapports de conformitÃ© et tableaux de bord dÃ©cisionnels

---

## ğŸ—ï¸ Architecture technique

### Stack technologique

| Composant | Technologie | Version | RÃ´le |
|-----------|-------------|---------|------|
| **Orchestration** | Apache Airflow | 3.1.0 | Orchestration des pipelines ELT |
| **Transformation** | dbt (Data Build Tool) | Latest | Transformations SQL modulaires et testables |
| **Data Warehouse** | PostgreSQL | 16 | Stockage OLAP avec schÃ©mas dimensionnels |
| **Task Queue** | Celery + Redis | Latest | ExÃ©cution distribuÃ©e des tÃ¢ches Airflow |
| **Conteneurisation** | Docker Compose | Latest | Infrastructure as Code |

### Architecture ELT

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OLTP Source       â”‚
â”‚  (TimescaleDB)      â”‚
â”‚  - Sites            â”‚
â”‚  - Devices          â”‚
â”‚  - Sensor Data      â”‚
â”‚  - Heartbeats       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Extract & Load (Airflow)
           â”‚ Ingestion incrÃ©mentale
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Layer         â”‚
â”‚  (PostgreSQL)       â”‚
â”‚  - raw_sites        â”‚
â”‚  - raw_devices      â”‚
â”‚  - raw_sensor_data  â”‚
â”‚  - raw_heartbeats   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Transform (dbt)
           â”‚ Staging â†’ Intermediate â†’ Marts
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Warehouse     â”‚
â”‚  (Star Schema)      â”‚
â”‚                     â”‚
â”‚  Dimensions:        â”‚
â”‚  - dim_sites        â”‚
â”‚  - dim_devices      â”‚
â”‚  - dim_dates        â”‚
â”‚  - dim_conformity   â”‚
â”‚                     â”‚
â”‚  Facts:             â”‚
â”‚  - fct_sensor_read  â”‚
â”‚  - fct_sensor_healthâ”‚
â”‚  - fct_compliance   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Business Views     â”‚
â”‚  - Compliance       â”‚
â”‚  - KPIs             â”‚
â”‚  - Dashboards       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SÃ©paration des environnements

Le projet fait partie d'un Ã©cosystÃ¨me complet :

```
ğŸ“¡ datayoti-esp32-firmware/      # Firmware IoT (ESP32 + capteurs DHT22)
    â””â”€â”€ Collecte des donnÃ©es en temps rÃ©el

ğŸ’¾ datayoti-mqtt-broker/         # Environnement OLTP opÃ©rationnel
    â”œâ”€â”€ MQTT Broker (ingestion)
    â””â”€â”€ TimescaleDB (stockage transactionnel)

ğŸ“Š datayoti-analytics/           # Environnement OLAP analytique â† CE PROJET
    â”œâ”€â”€ Apache Airflow (orchestration)
    â”œâ”€â”€ dbt (transformations)
    â””â”€â”€ PostgreSQL (Data Warehouse)
```

---

## ğŸ“ ModÃ¨le de donnÃ©es

### Approche dimensionnelle (Star Schema)

Le Data Warehouse implÃ©mente une **modÃ©lisation en Ã©toile** selon la mÃ©thodologie Kimball :

#### ğŸŒŸ Tables de dimensions

| Dimension | Description | Type | Grain |
|-----------|-------------|------|-------|
| **dim_sites** | Sites de dÃ©ploiement des capteurs | SCD2 | 1 ligne par version de site |
| **dim_devices** | Appareils IoT (ESP32 + DHT22) | SCD2 | 1 ligne par version d'appareil |
| **dim_dates** | Calendrier (1990-2050) | Static | 1 ligne par jour |
| **dim_conformity_rules** | RÃ¨gles de conformitÃ© mÃ©tier | SCD2 | 1 ligne par version de rÃ¨gle |

**SCD Type 2** : Historisation complÃ¨te des changements avec colonnes `valid_from_ts`, `valid_to_ts`, `is_current`

#### ğŸ“Š Tables de faits

| Fait | Grain | MÃ©triques | FrÃ©quence |
|------|-------|-----------|-----------|
| **fct_daily_sensor_reading** | 1 ligne par capteur par jour | Temp (min/max/avg), Humidity (min/max/avg) | Quotidien |
| **fct_daily_sensor_health** | 1 ligne par capteur par jour | RSSI, Heap, Uptime, NTP sync | Quotidien |
| **fct_daily_site_compliance** | 1 ligne par rÃ¨gle par site par jour | ConformitÃ© (boolÃ©en), mÃ©triques calculÃ©es | Quotidien |

#### ğŸ“ˆ Vues mÃ©tier

- **vw_daily_site_compliance_summary** : Taux de conformitÃ© global et violations critiques par site

### HiÃ©rarchies analytiques

```
Site
 â””â”€â”€ Device (n:1)
      â””â”€â”€ Sensor Reading (n:1)
      â””â”€â”€ Sensor Health (n:1)

Site + Date
 â””â”€â”€ Compliance Metrics (n:1)
      â””â”€â”€ Rule Evaluation (n:n)
```

---

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis

- **Docker** et **Docker Compose** installÃ©s
- **4 GB RAM** minimum disponible
- **2 CPUs** minimum
- Environnement **datayoti-mqtt-broker** en fonctionnement (source OLTP)

### Installation en 3 Ã©tapes

#### 1ï¸âƒ£ Configuration de l'environnement

```bash
# Cloner le projet
git clone https://github.com/medkan01/datayoti-analytics.git
cd datayoti-analytics

# CrÃ©er le fichier .env depuis le template
cp .env.example .env

# Ã‰diter les variables d'environnement
nano .env  # ou votre Ã©diteur prÃ©fÃ©rÃ©
```

**Variables essentielles Ã  configurer :**

```bash
# Base de donnÃ©es Data Warehouse (OLAP)
DM_PG_USER=datamart_admin
DM_PG_PASSWORD=VotreMotDePasseSecurise123!
DM_PG_DATABASE=datayoti_datamart
DM_PG_PORT=5433

# Connexion vers la source OLTP (TimescaleDB)
OLTP_PG_HOST=192.168.x.x  # IP de votre broker MQTT
OLTP_PG_PORT=5432
OLTP_PG_USER=mqtt_ingestor
OLTP_PG_PASSWORD=MotDePasseOLTP123!
OLTP_PG_DATABASE=datayoti_db

# Airflow
AIRFLOW_UID=50000
AIRFLOW__CORE__FERNET_KEY=<gÃ©nÃ©rer avec: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())">
```

#### 2ï¸âƒ£ DÃ©marrage de l'infrastructure

```bash
# Initialiser et dÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier l'Ã©tat des services
docker-compose ps

# Attendre l'initialisation complÃ¨te (~2 minutes)
docker-compose logs -f airflow-init
```

#### 3ï¸âƒ£ Configuration d'Airflow

1. AccÃ©der Ã  l'interface Airflow : **http://localhost:8080**
   - Username : `airflow`
   - Password : `airflow`

2. Configurer les connexions (Admin â†’ Connections) :

**Connexion OLTP (source)** :
```
Connection Id: oltp_connection
Connection Type: Postgres
Host: <OLTP_PG_HOST>
Schema: <OLTP_PG_DATABASE>
Login: <OLTP_PG_USER>
Password: <OLTP_PG_PASSWORD>
Port: <OLTP_PG_PORT>
```

**Connexion OLAP (destination)** :
```
Connection Id: olap_connection
Connection Type: Postgres
Host: datamart-db
Schema: public
Login: <DM_PG_USER>
Password: <DM_PG_PASSWORD>
Port: 5432
```

3. Activer les DAGs souhaitÃ©s et dÃ©clencher `ingest_raw_iot_data`

---

## ğŸ“‹ Pipelines de donnÃ©es

### DAGs Airflow

| DAG | FrÃ©quence | Description | DÃ©pendances |
|-----|-----------|-------------|-------------|
| **ingest_raw_iot_data** | @daily | Ingestion incrÃ©mentale depuis OLTP vers raw layer | Connexion OLTP |
| **dim_reference_iot** | @daily | Construction/mise Ã  jour des dimensions | ingest_raw_iot_data |
| **daily_facts_sensor** | @daily | AgrÃ©gation des faits quotidiens | dim_reference_iot |
| **dbt_housekeeping** | @weekly | Maintenance et optimisation dbt | - |
| **clear_tables** | Manual | RÃ©initialisation complÃ¨te (dÃ©veloppement) | - |

### Architecture dbt (4 couches)

```
ğŸ“ models/
â”‚
â”œâ”€â”€ ğŸ“‚ raw/                    # Couche 1: Tables brutes (DDL uniquement)
â”‚   â”œâ”€â”€ raw_sites.sql          # Structure vide pour ingestion Airflow
â”‚   â”œâ”€â”€ raw_devices.sql
â”‚   â”œâ”€â”€ raw_sensor_data.sql
â”‚   â””â”€â”€ raw_device_heartbeats.sql
â”‚
â”œâ”€â”€ ğŸ“‚ staging/                # Couche 2: Nettoyage et standardisation
â”‚   â”œâ”€â”€ stg_sites.sql          # Conversion types, validation, nettoyage
â”‚   â”œâ”€â”€ stg_devices.sql        # Format MAC addresses, timestamps
â”‚   â”œâ”€â”€ stg_sensor_data.sql    # Validation plages tempÃ©rature/humiditÃ©
â”‚   â”œâ”€â”€ stg_device_heartbeats.sql
â”‚   â””â”€â”€ stg_conformity_rules.sql
â”‚
â”œâ”€â”€ ğŸ“‚ intermediate/           # Couche 3: Logique mÃ©tier
â”‚   â”œâ”€â”€ int_sites_scd2.sql     # ImplÃ©mentation SCD2 via snapshots
â”‚   â”œâ”€â”€ int_devices_scd2.sql
â”‚   â”œâ”€â”€ int_conformity_rules_scd2.sql
â”‚   â”œâ”€â”€ int_daily_sensor_reading.sql    # AgrÃ©gations quotidiennes
â”‚   â”œâ”€â”€ int_daily_sensor_health.sql
â”‚   â””â”€â”€ int_daily_site_env.sql          # MÃ©triques environnementales
â”‚
â””â”€â”€ ğŸ“‚ marts/                  # Couche 4: ModÃ¨le dimensionnel
    â”œâ”€â”€ ğŸŒŸ Dimensions
    â”‚   â”œâ”€â”€ dim_sites.sql
    â”‚   â”œâ”€â”€ dim_devices.sql
    â”‚   â”œâ”€â”€ dim_dates.sql
    â”‚   â””â”€â”€ dim_conformity_rules.sql
    â”‚
    â”œâ”€â”€ ğŸ“Š Facts
    â”‚   â”œâ”€â”€ fct_daily_sensor_reading.sql
    â”‚   â”œâ”€â”€ fct_daily_sensor_health.sql
    â”‚   â””â”€â”€ fct_daily_site_compliance.sql
    â”‚
    â””â”€â”€ ğŸ“ˆ Views
        â””â”€â”€ vw_daily_site_compliance_summary.sql
```

### Exemple de requÃªte analytique

```sql
-- Taux de conformitÃ© mensuel par site
SELECT 
    s.site_name,
    d.year_number,
    d.month_name,
    ROUND(AVG(c.compliance_rate) * 100, 2) AS avg_compliance_pct,
    SUM(c.nb_critical_violations) AS total_critical_violations
FROM vw_daily_site_compliance_summary c
JOIN dim_sites s ON c.site_sk = s.site_sk AND s.is_current = TRUE
JOIN dim_dates d ON c.event_day_sk = d.date_sk
WHERE d.year_number = 2025
GROUP BY s.site_name, d.year_number, d.month_name
ORDER BY d.year_number, d.month_number, s.site_name;
```

---

## ğŸ› ï¸ DÃ©veloppement et maintenance

### Commandes dbt

Toutes les commandes dbt s'exÃ©cutent dans le conteneur Airflow :

```bash
# AccÃ©der au conteneur
docker-compose exec airflow-scheduler bash

# Naviguer vers le projet dbt
cd /opt/airflow/datayoti_dbt

# Tester la connexion
dbt debug

# Compiler les modÃ¨les (gÃ©nÃ¨re SQL dans target/)
dbt compile

# ExÃ©cuter tous les modÃ¨les
dbt run

# ExÃ©cuter un modÃ¨le spÃ©cifique
dbt run --select dim_sites

# ExÃ©cuter une couche
dbt run --select staging.*
dbt run --select marts.*

# ExÃ©cuter avec dÃ©pendances
dbt run --select +fct_daily_sensor_reading  # inclut upstream
dbt run --select fct_daily_sensor_reading+  # inclut downstream

# Tests de qualitÃ©
dbt test                           # Tous les tests
dbt test --select staging.*        # Tests sur staging
dbt test --select dim_sites        # Tests sur un modÃ¨le

# GÃ©nÃ©rer et servir la documentation
dbt docs generate
dbt docs serve --port 8081

# Snapshots (historisation SCD2)
dbt snapshot

# Charger les seeds (donnÃ©es de rÃ©fÃ©rence)
dbt seed
```

### Commandes Airflow

```bash
# Lister les DAGs
docker-compose exec airflow-scheduler airflow dags list

# DÃ©clencher un DAG manuellement
docker-compose exec airflow-scheduler airflow dags trigger ingest_raw_iot_data

# Voir les tÃ¢ches d'un DAG
docker-compose exec airflow-scheduler airflow tasks list ingest_raw_iot_data

# Afficher le statut d'une exÃ©cution
docker-compose exec airflow-scheduler airflow dags list-runs -d ingest_raw_iot_data

# Tester une tÃ¢che spÃ©cifique
docker-compose exec airflow-scheduler airflow tasks test ingest_raw_iot_data bootstrap_raw_schema 2025-11-03

# Pause/unpause un DAG
docker-compose exec airflow-scheduler airflow dags pause ingest_raw_iot_data
docker-compose exec airflow-scheduler airflow dags unpause ingest_raw_iot_data
```

### Gestion des logs

```bash
# Logs en temps rÃ©el d'un service
docker-compose logs -f airflow-scheduler
docker-compose logs -f datamart-db

# Logs d'une tÃ¢che Airflow spÃ©cifique
docker-compose exec airflow-scheduler airflow tasks logs ingest_raw_iot_data bootstrap_raw_schema 2025-11-03

# Logs dbt (dans le conteneur)
cd /opt/airflow/datayoti_dbt
cat logs/dbt.log
```

---

## ğŸ“Š MÃ©triques et analyses disponibles

### MÃ©triques environnementales

- **TempÃ©rature** :
  - Moyenne, minimum, maximum par site/appareil/jour
  - Plage de variation (tempÃ©rature_range)
  - StabilitÃ© thermique (Ã©cart min-max)

- **HumiditÃ©** :
  - Moyenne, minimum, maximum par site/appareil/jour
  - Plage de variation (humidity_range)
  - Respect des seuils plancher/plafond

### MÃ©triques de santÃ© IoT

- **ConnectivitÃ©** :
  - RSSI (Received Signal Strength Indicator)
  - Taux de disponibilitÃ© (uptime_ratio)
  - Synchronisation NTP

- **Performance systÃ¨me** :
  - MÃ©moire heap libre (free_heap)
  - MÃ©moire heap minimale (min_heap)
  - Temps de fonctionnement (uptime)

### ConformitÃ© mÃ©tier

Les rÃ¨gles de conformitÃ© sont dÃ©finies dans `seeds/conformity_rules.csv` :

| Type de mÃ©trique | Description | Exemple de rÃ¨gle |
|------------------|-------------|------------------|
| **temperature_range** | Plage tempÃ©rature acceptable | 18Â°C - 24Â°C |
| **humidity_ceiling** | Seuil maximum humiditÃ© | â‰¤ 60% |
| **humidity_floor** | Seuil minimum humiditÃ© | â‰¥ 35% |
| **temperature_stability** | Variation maximale autorisÃ©e | â‰¤ 3Â°C |
| **uptime_ratio** | DisponibilitÃ© minimale | â‰¥ 95% |
| **data_validity** | Taux de donnÃ©es valides | â‰¥ 90% |

Chaque rÃ¨gle est associÃ©e Ã  un **niveau de criticitÃ©** (LOW, MEDIUM, HIGH) pour prioriser les alertes.

---

## ğŸ” AccÃ¨s aux interfaces

| Interface | URL | Credentials | Description |
|-----------|-----|-------------|-------------|
| **Airflow Web UI** | http://localhost:8080 | airflow / airflow | Monitoring des DAGs et pipelines |
| **Flower (Celery)** | http://localhost:5555 | - | Monitoring des workers Celery |
| **PostgreSQL DataMart** | localhost:5433 | `DM_PG_USER` / `DM_PG_PASSWORD` | Connexion directe au DWH |
| **dbt Docs** | http://localhost:8081 | - | Documentation gÃ©nÃ©rÃ©e (si `dbt docs serve` actif) |

### Connexion au Data Warehouse

```bash
# Via psql
psql -h localhost -p 5433 -U datamart_admin -d datayoti_datamart

# Via DBeaver, pgAdmin, DataGrip, etc.
Host: localhost
Port: 5433
Database: datayoti_datamart
User: datamart_admin
Password: <DM_PG_PASSWORD>
```

---

## ğŸ“ Structure du projet

```
datayoti-analytics/
â”‚
â”œâ”€â”€ ğŸ“„ .env.example                 # Template de configuration
â”œâ”€â”€ ğŸ“„ .gitignore                   # Exclusions Git
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Infrastructure complÃ¨te
â”œâ”€â”€ ğŸ“„ README.md                    # Cette documentation
â”‚
â”œâ”€â”€ ğŸ“‚ airflow/                     # Apache Airflow
â”‚   â”œâ”€â”€ ğŸ“‚ config/
â”‚   â”‚   â””â”€â”€ airflow.cfg             # Configuration Airflow
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ dags/                    # Pipelines d'orchestration
â”‚   â”‚   â”œâ”€â”€ ingest_raw_iot_data.py  # Ingestion OLTP â†’ Raw
â”‚   â”‚   â”œâ”€â”€ dim_reference_iot.py    # Construction dimensions
â”‚   â”‚   â”œâ”€â”€ daily_facts_sensor.py   # AgrÃ©gation quotidienne
â”‚   â”‚   â”œâ”€â”€ dbt_housekeeping.py     # Maintenance dbt
â”‚   â”‚   â”œâ”€â”€ clear_tables.py         # Utilitaires reset
â”‚   â”‚   â””â”€â”€ utils/                  # Fonctions partagÃ©es
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ logs/                    # Logs Airflow (ignorÃ©s par git)
â”‚   â””â”€â”€ ğŸ“‚ plugins/                 # Plugins Airflow personnalisÃ©s
â”‚
â””â”€â”€ ğŸ“‚ datayoti_dbt/                # Projet dbt
    â”‚
    â”œâ”€â”€ ğŸ“„ dbt_project.yml          # Configuration projet
    â”œâ”€â”€ ğŸ“„ packages.yml             # DÃ©pendances (dbt_utils, dbt_date)
    â”‚
    â”œâ”€â”€ ğŸ“‚ profiles/
    â”‚   â””â”€â”€ profiles.yml            # Connexion PostgreSQL
    â”‚
    â”œâ”€â”€ ğŸ“‚ models/                  # ModÃ¨les de transformation
    â”‚   â”œâ”€â”€ ğŸ“‚ raw/                 # DDL tables brutes
    â”‚   â”‚   â”œâ”€â”€ _raw.yml            # Documentation
    â”‚   â”‚   â””â”€â”€ *.sql               # 4 modÃ¨les
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“‚ staging/             # Nettoyage et standardisation
    â”‚   â”‚   â”œâ”€â”€ _stg.yml            # Documentation + tests
    â”‚   â”‚   â””â”€â”€ *.sql               # 5 modÃ¨les
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“‚ intermediate/        # Logique mÃ©tier
    â”‚   â”‚   â”œâ”€â”€ _int.yml            # Documentation + tests
    â”‚   â”‚   â””â”€â”€ *.sql               # 8 modÃ¨les
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“‚ marts/               # Star Schema final
    â”‚   â”‚   â”œâ”€â”€ _marts.yml          # Documentation + tests
    â”‚   â”‚   â””â”€â”€ *.sql               # 8 modÃ¨les (4 dims + 3 facts + 1 view)
    â”‚   â”‚
    â”‚   â””â”€â”€ ğŸ“‚ sources/
    â”‚       â””â”€â”€ raw_iot.yml         # DÃ©finition sources externes
    â”‚
    â”œâ”€â”€ ğŸ“‚ macros/                  # Macros SQL rÃ©utilisables
    â”‚   â”œâ”€â”€ generate_schema_name.sql
    â”‚   â””â”€â”€ test_valid_mac_address.sql
    â”‚
    â”œâ”€â”€ ğŸ“‚ tests/                   # Tests personnalisÃ©s
    â”‚   â””â”€â”€ .gitkeep
    â”‚
    â”œâ”€â”€ ğŸ“‚ seeds/                   # DonnÃ©es de rÃ©fÃ©rence
    â”‚   â”œâ”€â”€ _seeds.yml
    â”‚   â””â”€â”€ conformity_rules.csv    # RÃ¨gles de conformitÃ© mÃ©tier
    â”‚
    â”œâ”€â”€ ğŸ“‚ snapshots/               # Historisation SCD2
    â”‚   â”œâ”€â”€ _snapshots.yml
    â”‚   â”œâ”€â”€ sites_snapshot.sql
    â”‚   â”œâ”€â”€ devices_snapshot.sql
    â”‚   â””â”€â”€ conformity_rules_snapshot.sql
    â”‚
    â”œâ”€â”€ ğŸ“‚ analyses/                # Analyses SQL ad-hoc
    â”‚   â””â”€â”€ .gitkeep
    â”‚
    â”œâ”€â”€ ğŸ“‚ target/                  # Artifacts compilÃ©s (ignorÃ© par git)
    â”œâ”€â”€ ğŸ“‚ logs/                    # Logs dbt (ignorÃ© par git)
    â””â”€â”€ ğŸ“‚ dbt_packages/            # Packages installÃ©s (ignorÃ© par git)
```

---

## ğŸš¨ DÃ©pannage

### ProblÃ¨mes courants

#### âŒ Erreur : "Connection refused" sur OLTP

```bash
# VÃ©rifier la connectivitÃ© rÃ©seau
ping <OLTP_PG_HOST>

# VÃ©rifier que le service OLTP est accessible
docker ps  # sur la machine OLTP

# Tester la connexion PostgreSQL
psql -h <OLTP_PG_HOST> -p <OLTP_PG_PORT> -U <OLTP_PG_USER> -d <OLTP_PG_DATABASE>
```

**Solution** : VÃ©rifier les variables `OLTP_PG_*` dans `.env` et les connexions Airflow

#### âŒ DAGs non visibles dans Airflow

```bash
# VÃ©rifier les logs du dag-processor
docker-compose logs airflow-dag-processor

# VÃ©rifier les erreurs de syntaxe Python
docker-compose exec airflow-scheduler python /opt/airflow/dags/<dag_file>.py
```

**Solution** : Corriger les erreurs de syntaxe, vÃ©rifier les imports

#### âŒ dbt : "Database Error" ou "Connection refused"

```bash
# Tester la configuration dbt
docker-compose exec airflow-scheduler bash
cd /opt/airflow/datayoti_dbt
dbt debug

# VÃ©rifier le fichier profiles.yml
cat profiles/profiles.yml
```

**Solution** : 
- VÃ©rifier que `host: datamart-db` (nom du service Docker)
- VÃ©rifier `port: 5432` (port interne du conteneur)
- VÃ©rifier les credentials dans profiles.yml

#### âŒ Erreurs de permissions Airflow

```bash
# RÃ©initialiser les permissions
docker-compose down
docker-compose up airflow-init
docker-compose up -d
```

#### âŒ Services ne dÃ©marrent pas

```bash
# VÃ©rifier les logs
docker-compose logs

# VÃ©rifier les ressources systÃ¨me
docker stats

# LibÃ©rer de l'espace disque
docker system prune -a
```

### Commandes de diagnostic

```bash
# Ã‰tat complet de l'infrastructure
docker-compose ps

# SantÃ© des services
docker-compose exec datamart-db pg_isready
docker-compose exec redis redis-cli ping

# Espace disque utilisÃ©
docker system df

# Logs en temps rÃ©el (tous services)
docker-compose logs -f --tail=100
```

---

## ğŸ” SÃ©curitÃ© et bonnes pratiques

### âš ï¸ Important pour la production

1. **Changer TOUS les mots de passe** par dÃ©faut
2. **RÃ©gÃ©nÃ©rer** la clÃ© Fernet Airflow :
   ```bash
   python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
   ```
3. **Ne JAMAIS commit** le fichier `.env` dans Git
4. **Utiliser des secrets managers** (AWS Secrets Manager, Vault, etc.)
5. **Activer SSL/TLS** pour les connexions PostgreSQL
6. **Restreindre l'accÃ¨s rÃ©seau** aux ports exposÃ©s (firewall)
7. **Configurer des backups rÃ©guliers** du Data Warehouse
8. **Mettre Ã  jour** rÃ©guliÃ¨rement les images Docker

### RÃ©seau Docker isolÃ©

Tous les services communiquent via le rÃ©seau Docker `analytics-net`, isolÃ© du rÃ©seau hÃ´te.

### Persistance des donnÃ©es

Les volumes Docker assurent la persistance :
- `postgres-db-volume` : Base Airflow
- `datamart_data` : Data Warehouse PostgreSQL

---

## ğŸ“š Ressources et rÃ©fÃ©rences

### Documentation officielle

- **Apache Airflow** : https://airflow.apache.org/docs/
- **dbt** : https://docs.getdbt.com/
- **PostgreSQL** : https://www.postgresql.org/docs/
- **Docker Compose** : https://docs.docker.com/compose/

### MÃ©thodologies

- **Kimball Dimensional Modeling** : Approche star schema
- **ELT vs ETL** : Load first, transform in database
- **SCD Type 2** : Historisation complÃ¨te des changements
- **dbt best practices** : Layered transformations (staging â†’ intermediate â†’ marts)

### DÃ©pendances dbt

- **dbt-utils** : Macros et tests gÃ©nÃ©riques
- **dbt-date** : GÃ©nÃ©ration de dimension calendrier

---

## ğŸ—ºï¸ Roadmap

### âœ… FonctionnalitÃ©s implÃ©mentÃ©es

- [x] Infrastructure Docker Compose complÃ¨te
- [x] Orchestration Airflow avec CeleryExecutor
- [x] Ingestion incrÃ©mentale depuis OLTP
- [x] ModÃ¨le dimensionnel en Ã©toile (4 dimensions, 3 faits)
- [x] Transformations dbt en 4 couches
- [x] Historisation SCD Type 2
- [x] Tests de qualitÃ© de donnÃ©es
- [x] Documentation inline complÃ¨te
- [x] MÃ©triques de conformitÃ© mÃ©tier

### ğŸ”„ En cours

- [ ] Tableaux de bord Grafana
- [ ] Alertes automatiques sur violations critiques
- [ ] Optimisation des performances (indexes, partitioning)

### ğŸ“‹ Ã€ venir

- [ ] Tests de donnÃ©es Ã©tendus (dbt expectations)
- [ ] Documentation dbt dÃ©ployÃ©e automatiquement
- [ ] CI/CD avec tests automatisÃ©s
- [ ] Monitoring avancÃ© (Prometheus + Grafana)
- [ ] Data lineage visualization
- [ ] API REST pour accÃ¨s programmatique
- [ ] Machine Learning pour prÃ©dictions

---

## ğŸ‘¨â€ğŸ’» Contribution

Ce projet est ouvert aux contributions. Pour proposer des amÃ©liorations :

1. Fork le repository
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

---

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

- **Apache Airflow** pour l'orchestration robuste
- **dbt Labs** pour le framework de transformation moderne
- **PostgreSQL Community** pour la base de donnÃ©es fiable
- **Kimball Group** pour la mÃ©thodologie dimensionnelle

---

**Projet DataYoti Analytics** - Une solution moderne de Data Warehouse pour l'IoT environnemental  
ğŸ“§ Contact : [GitHub Issues](https://github.com/medkan01/datayoti-analytics/issues)
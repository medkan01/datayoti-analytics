# DataYoti Analytics

Environnement d'analyse et de Business Intelligence pour le projet DataYoti, utilisant une architecture moderne ELT avec Apache Airflow et dbt.

## ğŸ—ï¸ Architecture

- **Environnement** : OLAP (Online Analytical Processing)
- **Base de donnÃ©es** : PostgreSQL 16 (Data Mart)
- **Orchestration** : Apache Airflow 3.1.0 avec CeleryExecutor
- **Transformation** : dbt (Data Build Tool)
- **ModÃ©lisation** : Star Schema avec approche Kimball
- **Visualisation** : Grafana Analytics
- **Cache** : Redis pour Airflow Celery

## ğŸ”„ SÃ©paration des environnements

```
datayoti-esp32-firmware/     # Sources de donnÃ©es (IoT)
    â”œâ”€â”€ Capteurs IoT
    â””â”€â”€ Firmware ESP32
datayoti-mqtt-broker/        # Environnement OLTP (opÃ©rationnel)
    â”œâ”€â”€ TimescaleDB
    â””â”€â”€ MQTT Broker
datayoti-analytics/          # Environnement OLAP (analytique) â† VOUS ÃŠTES ICI
    â”œâ”€â”€ PostgreSQL Data Mart
    â”œâ”€â”€ Apache Airflow
    â””â”€â”€ dbt Core
```

## ğŸš€ Installation

### PrÃ©requis

- Docker et Docker Compose
- Au moins 4GB de RAM disponible
- Au moins 2 CPUs
- Environnement `datayoti-mqtt-broker` dÃ©jÃ  en fonctionnement

### Configuration

1. **CrÃ©ez votre fichier `.env`** :
   ```bash
   cp .env.example .env
   ```

2. **Modifiez les variables d'environnement** dans `.env` :
   ```bash
   # Base de donnÃ©es Data Mart
   DM_PG_USER=datamart_admin
   DM_PG_PASSWORD=VotreMotDePasse_DataMart_2024!
   DM_PG_DATABASE=datayoti_datamart
   DM_PG_PORT=5433

   # Connexion vers l'environnement OLTP
   OLTP_PG_HOST=localhost
   OLTP_PG_PORT=5432
   OLTP_PG_USER=mqtt_ingestor
   OLTP_PG_PASSWORD=VotreMotDePasse_OLTP_2024!
   OLTP_PG_DATABASE=datayoti_db
   ```

3. **Configurez les connexions Airflow** :
   - Connexion `oltp_connection` : Base source (TimescaleDB)
   - Connexion `olap_connection` : Base cible (PostgreSQL Data Mart)

### DÃ©marrage

```bash
# DÃ©marrer l'infrastructure complÃ¨te
docker-compose up -d

# VÃ©rifier le statut des services
docker-compose ps

# Suivre les logs
docker-compose logs -f
```

## ğŸŒ AccÃ¨s aux interfaces

- **Apache Airflow** : http://localhost:8080
  - Utilisateur : `airflow`
  - Mot de passe : `airflow`
- **PostgreSQL Data Mart** : `localhost:5433`
- **Flower (Monitoring Celery)** : http://localhost:5555 (optionnel)

## ğŸ“Š Pipeline de donnÃ©es (ELT)

### 1. Extraction et Chargement (Airflow)

Les DAGs Airflow orchestrent l'ingestion des donnÃ©es depuis l'environnement OLTP :

#### DAG `ingest_raw_iot_data`
- **FrÃ©quence** : Quotidienne
- **Fonction** : Ingestion incrÃ©mentale des donnÃ©es brutes
- **Tables sources** :
  - `sites` â†’ `raw.raw_sites`
  - `devices` â†’ `raw.raw_devices`
  - `device_heartbeats` â†’ `raw.raw_device_heartbeats`
  - `sensor_data` â†’ `raw.raw_sensor_data`

#### Autres DAGs
- `dim_reference_iot` : Construction des dimensions de rÃ©fÃ©rence
- `daily_facts_sensor` : AgrÃ©gation des faits quotidiens
- `dbt_housekeeping` : Maintenance et nettoyage
- `clear_tables` : Utilitaires de gestion

### 2. Transformation (dbt)

Architecture dbt en couches selon les meilleures pratiques :

```
datayoti_dbt/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ raw/           # DonnÃ©es brutes (sources)
â”‚   â”œâ”€â”€ staging/       # Nettoyage et standardisation
â”‚   â”‚   â”œâ”€â”€ stg_sites.sql
â”‚   â”‚   â”œâ”€â”€ stg_devices.sql
â”‚   â”‚   â”œâ”€â”€ stg_device_heartbeats.sql
â”‚   â”‚   â”œâ”€â”€ stg_sensor_data.sql
â”‚   â”‚   â””â”€â”€ stg_conformity_rules.sql
â”‚   â”œâ”€â”€ intermediate/  # Logique mÃ©tier intermÃ©diaire
â”‚   â””â”€â”€ marts/         # ModÃ¨les dimensionnels finaux
â”‚       â”œâ”€â”€ dim_sites.sql
â”‚       â”œâ”€â”€ dim_devices.sql
â”‚       â”œâ”€â”€ dim_dates.sql
â”‚       â”œâ”€â”€ dim_conformity_rules.sql
â”‚       â”œâ”€â”€ fct_daily_sensor_reading.sql
â”‚       â”œâ”€â”€ fct_daily_sensor_health.sql
â”‚       â”œâ”€â”€ fct_daily_site_compliance.sql
â”‚       â””â”€â”€ vw_daily_site_compliance_summary.sql
```

### 3. ModÃ¨le dimensionnel (Star Schema)

#### Dimensions
- **`dim_sites`** : Sites IoT avec mÃ©tadonnÃ©es
- **`dim_devices`** : Appareils IoT et caractÃ©ristiques
- **`dim_dates`** : Dimension temporelle
- **`dim_conformity_rules`** : RÃ¨gles de conformitÃ© mÃ©tier

#### Faits
- **`fct_daily_sensor_reading`** : Lectures quotidiennes des capteurs
- **`fct_daily_sensor_health`** : SantÃ© quotidienne des capteurs
- **`fct_daily_site_compliance`** : ConformitÃ© quotidienne des sites

#### Vues mÃ©tier
- **`vw_daily_site_compliance_summary`** : Tableau de bord de conformitÃ©

## ğŸ› ï¸ DÃ©veloppement

### Commandes dbt utiles

```bash
# AccÃ©der au conteneur Airflow
docker-compose exec airflow-scheduler bash

# Naviguer vers le projet dbt
cd /opt/airflow/datayoti_dbt

# Tester les connexions
dbt debug

# Compiler les modÃ¨les
dbt compile

# ExÃ©cuter tous les modÃ¨les
dbt run

# ExÃ©cuter les tests
dbt test

# GÃ©nÃ©rer la documentation
dbt docs generate
dbt docs serve
```

### Airflow CLI

```bash
# Lister les DAGs
docker-compose exec airflow-scheduler airflow dags list

# DÃ©clencher un DAG manuellement
docker-compose exec airflow-scheduler airflow dags trigger ingest_raw_iot_data

# Voir les tÃ¢ches d'un DAG
docker-compose exec airflow-scheduler airflow tasks list ingest_raw_iot_data
```

## ğŸ“ Structure complÃ¨te du projet

```
datayoti-analytics/
â”œâ”€â”€ .env.example                    # Template variables d'environnement
â”œâ”€â”€ .gitignore                      # Exclusions Git optimisÃ©es
â”œâ”€â”€ docker-compose.yml              # Infrastructure complÃ¨te
â”œâ”€â”€ README.md                       # Cette documentation
â”œâ”€â”€ airflow/                        # Configuration Apache Airflow
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ airflow.cfg            # Configuration Airflow
â”‚   â”œâ”€â”€ dags/                      # Pipelines d'orchestration
â”‚   â”‚   â”œâ”€â”€ ingest_raw_iot_data.py # Ingestion donnÃ©es IoT
â”‚   â”‚   â”œâ”€â”€ dim_reference_iot.py   # Construction dimensions
â”‚   â”‚   â”œâ”€â”€ daily_facts_sensor.py  # AgrÃ©gation faits
â”‚   â”‚   â”œâ”€â”€ dbt_housekeeping.py    # Maintenance dbt
â”‚   â”‚   â”œâ”€â”€ clear_tables.py        # Utilitaires
â”‚   â”‚   â””â”€â”€ utils/                 # Fonctions communes
â”‚   â”œâ”€â”€ logs/                      # Logs Airflow
â”‚   â””â”€â”€ plugins/                   # Plugins personnalisÃ©s
â””â”€â”€ datayoti_dbt/                  # Projet dbt
    â”œâ”€â”€ dbt_project.yml            # Configuration projet
    â”œâ”€â”€ profiles/
    â”‚   â””â”€â”€ profiles.yml           # Connexions bases de donnÃ©es
    â”œâ”€â”€ models/                    # ModÃ¨les de transformation
    â”‚   â”œâ”€â”€ raw/                   # Sources de donnÃ©es
    â”‚   â”œâ”€â”€ staging/               # Couche de nettoyage
    â”‚   â”œâ”€â”€ intermediate/          # Logique mÃ©tier
    â”‚   â””â”€â”€ marts/                 # ModÃ¨les dimensionnels
    â”œâ”€â”€ macros/                    # Macros dbt rÃ©utilisables
    â”œâ”€â”€ tests/                     # Tests de qualitÃ© donnÃ©es
    â”œâ”€â”€ seeds/                     # DonnÃ©es de rÃ©fÃ©rence
    â””â”€â”€ snapshots/                 # Historisation SCD
```

## ğŸ”§ Services Docker

| Service | Description | Port | SantÃ© |
|---------|-------------|------|--------|
| `postgres` | Base Airflow | - | pg_isready |
| `redis` | Cache Celery | 6379 | redis-cli ping |
| `airflow-apiserver` | API Airflow | 8080 | curl /api/v2/version |
| `airflow-scheduler` | Ordonnanceur | - | curl /health |
| `airflow-dag-processor` | Processeur DAGs | - | jobs check |
| `airflow-worker` | Worker Celery | - | celery inspect ping |
| `airflow-triggerer` | DÃ©clencheur | - | jobs check |
| `datamart-db` | PostgreSQL Data Mart | 5433 | - |

## ğŸ“ˆ MÃ©triques et monitoring

### MÃ©triques IoT disponibles
- **TempÃ©rature** : Min/Max/Moyenne par site et pÃ©riode
- **HumiditÃ©** : Min/Max/Moyenne par site et pÃ©riode
- **Uptime** : Ratio de disponibilitÃ© des capteurs
- **ConformitÃ©** : Respect des rÃ¨gles mÃ©tier par site
- **SantÃ© systÃ¨me** : Heartbeats et diagnostics

### RÃ¨gles de conformitÃ©
- **Plage tempÃ©rature** : VÃ©rification des seuils min/max
- **Seuil humiditÃ©** : Plancher et plafond d'humiditÃ©
- **StabilitÃ© tempÃ©rature** : Variation maximale autorisÃ©e
- **Taux uptime** : DisponibilitÃ© minimale requise
- **ValiditÃ© donnÃ©es** : Pourcentage de donnÃ©es valides

## ğŸš¨ Troubleshooting

### ProblÃ¨mes courants

1. **Erreur de connexion dbt** :
   ```bash
   # VÃ©rifier la configuration des profils
   cat datayoti_dbt/profiles/profiles.yml
   ```

2. **DAGs non visibles** :
   ```bash
   # VÃ©rifier les logs du dag-processor
   docker-compose logs airflow-dag-processor
   ```

3. **ProblÃ¨mes de permissions** :
   ```bash
   # RedÃ©marrer l'initialisation
   docker-compose up airflow-init
   ```

### Logs utiles

```bash
# Logs Airflow complets
docker-compose logs -f airflow-scheduler

# Logs d'un DAG spÃ©cifique
docker-compose exec airflow-scheduler airflow tasks log ingest_raw_iot_data bootstrap_raw_schema

# Logs PostgreSQL Data Mart
docker-compose logs datamart-db
```

## ğŸ” SÃ©curitÃ©

- Tous les mots de passe doivent Ãªtre changÃ©s en production
- Les connexions entre services utilisent des rÃ©seaux Docker isolÃ©s
- Les volumes persistent les donnÃ©es en cas de redÃ©marrage
- Fichier `.env` exclu du contrÃ´le de version

## ğŸš€ Prochaines Ã©tapes

1. **âœ… Infrastructure** : Airflow + dbt + PostgreSQL opÃ©rationnels
2. **âœ… Ingestion** : Pipelines d'extraction depuis OLTP
3. **âœ… Transformation** : ModÃ¨les dbt en couches
4. **ğŸ”„ En cours** : Tableaux de bord Grafana
5. **ğŸ“‹ Ã€ venir** : Tests de qualitÃ© Ã©tendus
6. **ğŸ“‹ Ã€ venir** : Alerting et monitoring avancÃ©
7. **ğŸ“‹ Ã€ venir** : Documentation dbt automatisÃ©e

---

**Note** : Cet environnement respecte les bonnes pratiques moderne d'architecture analytique avec sÃ©paration OLTP/OLAP, orchestration dÃ©clarative et transformation en code.